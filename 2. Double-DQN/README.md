# 1.Main Idea
There is only one modification based on DQN: In DQN, the target_q_net selects the action with the maximum value in the next state, and then its Q-value is calculated (this approach can lead to overestimation issues). In Double-DQN, the q_net selects the action with the maximum value, and then the target_q_net is used to calculate the Q-value.